{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# configuration\n",
    "base_url = 'https://vietnamnet.vn/'\n",
    "# Supported categories: 'thoi-su', 'kinh-doanh', 'van-hoa', 'giao-duc', 'the-gioi', 'the-thao', 'giai-tri', 'doi-song', 'suc-khoe'\n",
    "categories = ['thoi-su', 'kinh-doanh', 'van-hoa', 'giao-duc','the-gioi'] \n",
    "number_of_articles = 10 # for each category\n",
    "\n",
    "number_of_all_articles = len(categories) * number_of_articles\n",
    "file_name = f\"{number_of_all_articles}baibao.txt\"\n",
    "categories_mapping = {\n",
    "    'thoi-su': 'Thời Sự',\n",
    "    'kinh-doanh': 'Kinh Doanh',\n",
    "    'van-hoa': 'Văn Hóa',\n",
    "    'giao-duc': 'Giáo Dục',\n",
    "    'the-gioi': 'Thế Giới',\n",
    "    'the-thao': 'Thể Thao',\n",
    "    'giai-tri': 'Giải Trí',\n",
    "    'chinh-tri': 'Chính Trị',\n",
    "    'doi-song': 'Đời Sống',\n",
    "    'suc-khoe': 'Sức Khỏe'\n",
    "}\n",
    " \n",
    "def get_article_links(base_url, url, max_articles):\n",
    "    \"\"\"\n",
    "    Returns a list of article links from the given url.\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    while len(links) < max_articles:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        for link in soup.find_all('div', class_='horizontalPost__main'):\n",
    "            find_h3 = link.find_next('h3', class_='horizontalPost__main-title vnn-title title-bold')\n",
    "            find_a = find_h3.find_next('a')\n",
    "            article_link = urljoin(base_url, find_a['href'])\n",
    "            links.append(article_link)\n",
    "        page_list = soup.find('ul', class_='pagination__list')\n",
    "        link_next_page = page_list.find_next('li', class_='pagination__list-item').find_next('a')\n",
    "        if link_next_page is None:\n",
    "            break\n",
    "        url = urljoin(url, link_next_page.get('href'))\n",
    "    return links[:max_articles]\n",
    "\n",
    "def get_article_content(links):\n",
    "    \"\"\"\n",
    "    Returns a list of article content from the given links.\n",
    "    \"\"\"\n",
    "    articles = []\n",
    "    for link in links:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        find_content = soup.find('div', class_='main-v1 bg-white')\n",
    "        title = find_content.find('h1', class_='content-detail-title').get_text()\n",
    "        content = find_content.find('div', class_='maincontent main-content')\n",
    "        if content is None:\n",
    "            content = find_content.find('div', class_='maincontent main-content content-full-image content-full-image-v1')\n",
    "        if content:\n",
    "            content_text = content.get_text()\n",
    "        else:\n",
    "            content_text = \"Can't get content\"\n",
    "        article = {\n",
    "            \"title\": title,\n",
    "            \"content\": content_text\n",
    "        }\n",
    "        articles.append(article)\n",
    "    return articles\n",
    "\n",
    "def crawl_and_save_articles(categories, file_name, number_of_articles):\n",
    "    with open(file_name, 'a', encoding='utf-8') as f:\n",
    "        for category in categories:\n",
    "            count = 1\n",
    "            mapped_category = categories_mapping.get(category, category)\n",
    "            f.write(f\"------------------------ Thể loại: {mapped_category} --------------------------\\n\")\n",
    "            url = urljoin(base_url, category)\n",
    "            links = get_article_links(base_url, url, number_of_articles)\n",
    "            articles = get_article_content(links)\n",
    "            for article in articles:\n",
    "                f.write(f\"Bài báo thứ {count}: \\n\")\n",
    "                f.write(f\"Tiêu đề: {article['title']}\\nNội dung: {article['content']}\\n\")\n",
    "                f.write('--------------------------------------------------\\n')\n",
    "                count += 1\n",
    "                \n",
    "crawl_and_save_articles(categories, file_name, number_of_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
